---
title: "Jacobian Calculations for nls()"
author:
  - Arkajyoti Bhattacharjee, Indian Institute of Technology, Kanpur
  - John C. Nash, University of Ottawa, Canada
date: "26/05/2021"
output: 
    pdf_document:
        keep_tex: false
        toc: true
bibliography: ImproveNLS.bib
---

<!-- - Heather Turner, University of Warwick, UK -->

```{r setup, include=FALSE}
rm(list=ls()) # clear the workspace for this document
knitr::opts_chunk$set(echo = TRUE)
## setup for this document
library(nlsr)  # So we have the analytic/symbolic derivatives
library(numDeriv) # numerical derivatives package
library(microbenchmark)  # timing

printsum <- function(xx){ print(summary(xx))} # May be needed
traceval  <-  TRUE  # traceval set TRUE to debug or give full history
#  Set to FALSE when we don't need extensive output
```

# ISSUES

- ExDerivs.R file causes a number of failures in the ORIGINAL numericDeriv.

- Need to verify nlsalt:: version of numericDeriv() matches all cases of nlspkg:: version

- Do we need to get a model frame? How? and How to use it?


## TODOS (mostly from nlsr vignette nlsr-devdoc.Rmd)

- how to insert numerical derivatives when Deriv unable to get result (nlsr)
- approximations for jacfn beyond fwd approximation. How to specify??
- how to force numerical approximations in nlfb() in a 
  manner consistent with that used in `optimx::optimr()`, that is, to
  surround the name of `jacfn` with quotes if it is a numerical approximation,
  or to provide a logical control to `nlxb()` for this purpose.

# Jacobians in nls()

This document source is in file **DerivsNLS.Rmd**.

`nls()` and other nonlinear least squares programs in R need a Jacobian matrix 
calculated at the current set of trial nonlinear model parameters to set up 
the Gauss-Newton equations or their stabilized modifications in methods such as
that of Marquardt (@Marquardt1963). Unfortunately, `nls()` calls
the Jacobian the "gradient", and uses function `numericDeriv()` to compute them.
This document is an attempt to describe different ways to compute the Jacobian
for use in nls() and related software, and to evaluate these approaches from
several perspectives.

In evaluating performance, we need to know the conditions under which the evaluation
was conducted. Thus the computations included in this document, which is built using
`Rmarkdown`, are specific to the computer in which the document is processed. We
will add tables that give the results for different computing environments at the
bottom.

# An example problem

We will use the Hobbs weed infestation problem (@jncnm79, page 120).

```{r hobbsex}
# Data for Hobbs problem
ydat  <-  c(5.308, 7.24, 9.638, 12.866, 17.069, 23.192, 31.443, 
            38.558, 50.156, 62.948, 75.995, 91.972) # for testing
tdat  <-  seq_along(ydat) # for testing

# A simple starting vector -- must have named parameters for nlxb, nls, wrapnlsr.
start1  <-  c(b1=1, b2=1, b3=1)
eunsc  <-   y ~ b1/(1+b2*exp(-b3*tt)) # formula -- display structure with str(eunsc)
# Can we convert a string form of this "model" to a formula
ceunsc <- " y ~ b1/(1+b2*exp(-b3*tt))" # This will give character form: str(ceunsc)
# Next line Will be TRUE if we have made the conversion OK
print(as.formula(ceunsc)==eunsc)
weeddata1  <-  data.frame(y=ydat, tt=tdat) ## LOCAL DATA IN DATA FRAMES
weedenv <- list2env(weeddata1) ## Put data in an Environment
# Add the parameter data as "variables" 
weedenv$b1 <- start1[[1]]; weedenv$b2 <- start1[[2]]; weedenv$b3 <- start1[[3]]
# Display content of the Environment with ## ls.str(weedenv)
# We are now set up for computations
```

# Tools for Jacobians

There are a number of ways to get the Jacobian in R.

## numericDeriv() original version from base R

`numericDeriv` is the R function used by `nls()` to evaluate Jacobians for its Gauss-Newton
equations. The R source code is in the file `nls.R`. It calls a C function numeric_deriv
in `nls.c`. These have been extracted in an R package form as `nlspkg` by Duncan Murdoch
as described in our document **PkgFromRbase.Rmd: Making a package from base R files**, and
we will use that version.

In the following we will test and time `numericDeriv()` along with various of its options.

```{r nd1}
rexpr<-call("-",eunsc[[3]], eunsc[[2]]) # Generate the residual "call"
res0<-eval(rexpr, weedenv) # Get the residuals
print(res0) # the base residuals
cat("Sumsquares at 1,1,1 is ",sum(res0^2),"\n")
rexpr<-call("-",eunsc[[3]], eunsc[[2]]) # This is the "call" that computes the residual
## Try the numericDeriv option
theta<-names(start1)
## suppressMessages(library(nlspkg))
suppressMessages(ndnls<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv))
print(ndnls)
print(sum(ndnls^2))
tndnls<-microbenchmark(ndnls<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv))
print(tndnls)

## numericDeriv also has central difference option, as well as choice of eps parameter
## Central diff
ndnlsc<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE)
print(ndnlsc)
print(sum(ndnlsc^2))
tndnlsc<-microbenchmark(ndnlsc<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE))
print(tndnlsc)

## Forward diff with smaller eps
ndnlsx<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, eps=1e-10)
print(ndnlsx)
print(sum(ndnlsx^2))
tndnlsx<-microbenchmark(ndnlsx<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, eps=1e-10))
print(tndnlsx)

## Central diff with smaller eps
ndnlscx<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE, eps=1e-10)
print(ndnlscx)
print(sum(ndnlscx^2))
tndnlscx<-microbenchmark(ndnlscx<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE, eps=1e-10))
print(tndnlscx)

## Add dir parameter -- the direction of the parameter shift
ndnlsd<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, dir=-1)
# Does dir make a difference? This might be accidental for forward difference.
max(abs(ndnlsd-ndnls))
ndnlscd<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE, dir=-1)
# Does dir make a difference? For central diff it should NOT!
max(abs(ndnlscd-ndnlsc))
```


## numericDeriv() alternative pure-R version

This version (see Appendix 2) has C code replaced with R equivalents.


```{r and1}
## Try ExDerivs.R ??
suppressMessages(andnls<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv))
# print(andnls); print(sum(andnls^2))
tandnls<-microbenchmark(andnls<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv))
print(tandnls)
## numericDeriv also has central difference option, as well as choice of eps parameter
## Central diff
andnlsc<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE)
ndnlsc<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE)
# print(andnlsc); print(sum(andnlsc^2))
tandnlsc<-microbenchmark(andnlsc<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE))
print(tandnlsc)

## Forward diff with smaller eps
andnlsx<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, eps=1e-10)
ndnlsx<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, eps=1e-10)
# print(andnlsx); print(sum(andnlsx^2))
tandnlsx<-microbenchmark(andnlsx<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, eps=1e-10))
print(tandnlsx)

## Central diff with smaller eps
andnlscx<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE, eps=1e-10)
ndnlscx<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE, eps=1e-10)
# print(andnlscx) ; print(sum(andnlscx^2))
tandnlscx<-microbenchmark(andnlscx<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE, eps=1e-10))
print(tandnlscx)

## Comparisons for Jacobian between nlspkg and nlsalt i.e. R&C vs just R
max(abs(attr(ndnls, "gradient")-attr(andnls,"gradient")))
max(abs(attr(ndnlsc, "gradient")-attr(andnlsc,"gradient")))
max(abs(attr(ndnlsx, "gradient")-attr(andnlsx,"gradient")))
max(abs(attr(ndnlscx, "gradient")-attr(andnlscx,"gradient")))

## Using dir
cat("eps (regular) = ",.Machine$double.eps^(1/2),
    "  eps (central) =",.Machine$double.eps^(1/3),"\n")
andnlsd<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, dir=-1)
max(abs(attr(andnlsd, "gradient")-attr(ndnls,"gradient")))
max(abs(attr(andnlsd, "gradient")-attr(andnls,"gradient")))
andnlscd<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE, dir=-1)
max(abs(attr(andnlscd, "gradient")-attr(ndnlsc,"gradient")))

## Try comparisons over different eps sizes
for (ee in 3:10){
andnlsd<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, dir=-1, eps=10^(-ee))
andnlscd<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE, dir=-1, eps=10^(-ee))
andnlsx<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, eps=10^(-ee))
andnlscx<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE, eps=10^(-ee))
cat("Regular diff, eps=10^(-",ee,"):",
      max(abs(attr(andnlsd,"gradient")-attr(andnlsx,"gradient"))),"\n")
cat("Central diff, eps=10^(-",ee,"):",
    max(abs(attr(andnlscd,"gradient")-attr(andnlscx,"gradient"))),"\n")
}
```

The `dir` parameter allows us to use a backward difference for the derivative. This 
appears in `nlsModel()` for the case where a parameter is on an upper bound for
the case `algorithm="port"`. It does not check for nearness to the bound, and 
for the lower bound assumes that we are stepping AWAY from the bound in the
default direction (`dir=+1`). None of the code addresses the issue where bounds
are closer together than the step used for the finite difference, so there are
situations where we could crash the code. Nor does the code check if the central
difference is specified when near a bound. 

- In the case of lower bounds, a central difference can overstep the bound when
  a parameter is "close" or on the bound.
- In the case of an upper bound, changing the `dir` will not change the central 
  derivative approximation expression and steps in both forward and backward 
  directions of the parameter are taken.
  
## Symbolic methods from `nlsr`

The package `nlsr` has a function `model2rjfun()` that converts an expression
describing how the residual functions are computed into an R function that
computes the residuals at a particular set of parameters and sets the 
**attribute** "gradient" of the vector of residual values to the Jacobian at
the particular set of parameters. 

```{r nlsr1}
# nlsr has function model2rjfun. We can evaluate just the residuals
res0<-model2rjfun(eunsc, start1, data=weeddata1, jacobian=FALSE)
res0(start1)
# or the residuals and jacobian
## nlsr::model2rjfun forms a function with gradient (jacobian) attribute
funsc <- model2rjfun(eunsc, start1, data=weeddata1) # from nlsr: creates a function
tmodel2rjfun <- microbenchmark(model2rjfun(eunsc, start1, data=weeddata1))
print(tmodel2rjfun)
print(funsc)
print(funsc(start1))
print(environment(funsc))
print(ls.str(environment(funsc)))
print(ls(environment(funsc)$data))
eval(eunsc, environment(funsc))
vfunsc<-funsc(start1)
print(vfunsc)
tfunsc<-microbenchmark(funsc(start1))
print(tfunsc)
```

# `numDeriv` package

The package `numDeriv` includes a function `jacobian()` that acts on a user
function `resid()` to produce the Jacobian at a set of parameters by several
choices of approximation. 

```{r numDeriv1}
# We use the residual function (without gradient attribute) from nlsr
jnlsc<-jacobian(res0, start1)
jnlsc
# Timings of the analytic jacobian calculations
tjnlsc<-microbenchmark(jnlsc<-jacobian(res0, start1))
print(tjnlsc)
```

Note that the manual pages for `numDeriv` offer many options for the functions in
the package. At 2021-5-27 we have yet to explore these.

# Comparisons

In the following, we are comparing to `vfunsc`, which is the evaluated 
residual vector at `start1=c(1,1,1)` with "gradient" attribute (jacobian)
included, as developed using package `nlsr`. This is taken as the "correct"
result, even though it is possible that the generated order of calculations
may introduce inaccuracies in the supposedly analytic derivatives.

`numericDeriv` computes a similar structure (residuals with "gradient" attribute):
`ndnlsc`: the forward difference result with default `eps` (1e-07 according to manual)
`ndnlsc2`: Central difference with default `eps`
`ndnlscx`: Forward difference with smaller eps=1e-10
`ndnlscx2`: Central difference with smaller eps=1e-10

`jnlsc`: numDeriv::jacobian() result with default settings.

```{r compjac1}
## Matrix comparisons
attr(ndnls, "gradient")-attr(vfunsc,"gradient")
attr(ndnlsc, "gradient")-attr(vfunsc,"gradient")
attr(ndnlsx, "gradient")-attr(vfunsc,"gradient")
attr(ndnlscx, "gradient")-attr(vfunsc,"gradient")
jnlsc-attr(vfunsc,"gradient")

## Summary comparisons
max(abs(attr(ndnls, "gradient")-attr(vfunsc,"gradient")))
max(abs(attr(ndnlsc, "gradient")-attr(vfunsc,"gradient")))
max(abs(attr(ndnlsx, "gradient")-attr(vfunsc,"gradient")))
max(abs(attr(ndnlscx, "gradient")-attr(vfunsc,"gradient")))
max(abs(jnlsc-attr(vfunsc,"gradient")))
```


# Performance results for different computing environments

Here we present tables of the results, preceded by identified descriptions of the machines we
used. We use ideas and functions from the document `MachineSummary` to provide a characterization
and identity for each machine used.

M21-LM20.1 

?? still to be run

?? What machines provide a range of possibilities.

# Discussion of derivative computation for nonlinear least squares

In no particular order, we comment on some issues relating to the Jacobian calculations
in nonlinear least squares.

## Nomenclature

R is not in step with many other areas of numerical computation when labelling different
objects in the nonlinear least squares problem. In particular, R uses the term "gradient"
when the object of interest is the Jacobian matrix. In that it is useful in performing 
iterations of the Gauss-Newton or related equations to have the Jacobian associated with
the residuals, and the rows of the Jacobian matrix are "gradients" of the respective
residuals, we can accept the attribute name "gradient" to select the required information.
Moreover, as in package `nlsr` it is very useful to have the Jacobian matrix as an 
attribute of the residual vector, since the main solver function, in this case `nlsr::nlfb()`,
can be called with the same input for the arguments `res` and `jac`. These are the functions
required to compute the residual and the Jacobian, and using the same function for both is
very convenient, but needs some way to return both the residual vector and Jacobian matrix
in a coherent fashion. 

## Numerical approximation near constraints

As far as we are aware there is no software that implements a fully safeguarded system to
compute numerical approximation of the Jacobian (or gradients in general optimization) near
constraints. The same statement applies even in the case of the much simpler bounds constraints.
Users have a perverse tendency to devise ways to foil our best efforts. For example, they may
decide that a good way to specify fixed (i.e., masked) parameters that they do not want to vary
during a particular calculation is to specify the lower and upper bound of a parameter at the
same value. Later runs may want the parameter constraints relaxed. 

In `nlsr::nlxb()`, users may, in fact, specify masked parameters this way. This is a case of 
"if you can't beat them, join them", but it does provide an easily understood way for users to
fix values. 

More tricky is dealing with constraints that are close together. Note that these may arise from,
for example, two linear (planar) constraints that approach at a narrow angle. In the apex where
these constraints intersect, we will have tight bounds on parameters. If the constraint is not
one that is imposed by the nature of the residual or objective function, for example, a log() 
or square root near zero, then we can generally proceed and allow the derivative approximator
to evaluate outside the constraints. Things are decidedly nastier if we do have inadmissible
values. 

The issue of constraints and the need for a step in parameter values for derivative approximations
was one of the motivations for trying to find analytic derivatives in package `nlsr` and the 
continuing effort to bring them into other R tools.

## A case where the initial Jacobian is singular

The following example shows that numericDeriv() does a reasonable job of computing
the Jacobian, but the result is still singular.

```{r code=xfun::read_utf8('badJlogmod.R')}
```


# Appendix 1: Base R numericDeriv code

This code is in two files, nls.R and nls.c and is extracted here.

## From nls.R

```{r nlsR, comment=NA, echo=FALSE}
   cat(readLines('./nls-numericDeriv.R'), sep = '\n')
```


## From nls.c

```{r nlsc, comment=NA, echo=FALSE}
   cat(readLines('./nls-numericDeriv.c'), sep = '\n')
```

# Appendix 2: numericDeriv() from nlsalt package (all in R)

```{r nlsndnew, comment=NA, echo=FALSE}
   cat(readLines('./nlsalt/R/nlsnd.R'), sep = '\n')
```
