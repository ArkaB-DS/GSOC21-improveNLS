---
title: "Jacobian Calculations for nls()"
author:
  - Arkajyoti Bhattacharjee, Indian Institute of Technology, Kanpur
  - John C. Nash, University of Ottawa, Canada
date: "26/05/2021"
output: pdf_document
bibliography: ImproveNLS.bib
---

<!-- - Heather Turner, University of Warwick, UK -->

```{r setup, include=FALSE}
rm(list=ls()) # clear the workspace for this document
knitr::opts_chunk$set(echo = TRUE)
## setup for this document
library(nlsr)  # So we have the analytic/symbolic derivatives
library(numDeriv) # numerical derivatives package
library(microbenchmark)  # timing

printsum <- function(xx){ print(summary(xx))} # May be needed
traceval  <-  TRUE  # traceval set TRUE to debug or give full history
#  Set to FALSE when we don't need extensive output
```

# ISSUES

- ExDerivs.R file causes a number of failures in the ORIGINAL numericDeriv.
- Need to verify nlsalt:: version matches all cases of nlspkg:: version


# Jacobians in nls()

`nls()` needs Jacobians calculated at the current set of trial nonlinear model
parameters to set up the Gauss-Newton equations. Unfortunately, `nls()` calls
the Jacobian the "gradient", and uses function `numericDerivs()` to compute them.
This document is an attempt to describe different ways to compute the Jacobian
for use in nls() and related software, and to evaluate the performance of these
approaches.

In evaluating performance, we need to know the conditions under which the evaluation
was conducted. Thus the computations included in this document, which is built using
`Rmarkdown`, are specific to the computer in which the document is processed. We
will add tables that give the results for different computing environments at the
bottom.

# An example problem

We will use the Hobbs weed infestation problem (@jncnm79, page 120).

```{r hobbsex}
# Data for Hobbs problem
ydat  <-  c(5.308, 7.24, 9.638, 12.866, 17.069, 23.192, 31.443, 
            38.558, 50.156, 62.948, 75.995, 91.972) # for testing
tdat  <-  seq_along(ydat) # for testing

# A simple starting vector -- must have named parameters for nlxb, nls, wrapnlsr.
start1  <-  c(b1=1, b2=1, b3=1)
eunsc  <-   y ~ b1/(1+b2*exp(-b3*tt))
str(eunsc)
# Can we convert a string form of this "model" to a formula
ceunsc <- " y ~ b1/(1+b2*exp(-b3*tt))"
str(ceunsc)

# Will be TRUE if we have made the conversion
print(as.formula(ceunsc)==eunsc)

## LOCAL DATA IN DATA FRAMES
weeddata1  <-  data.frame(y=ydat, tt=tdat)

## Put data in an Environment
weedenv <- list2env(weeddata1)
weedenv$b1 <- start1[[1]]
weedenv$b2 <- start1[[2]]
weedenv$b3 <- start1[[3]]
# Display content of the Environment
## Note that may need to do further commands to get everything
ls.str(weedenv)
# Generate the residual "call"
rexpr<-call("-",eunsc[[3]], eunsc[[2]])
# Get the residuals
r0<-eval(rexpr, weedenv)
print(r0)
cat("Sumsquares at 1,1,1 is ",sum(r0^2),"\n")

## Another way
ldata<-list2env(as.list(start1),envir=weedenv)
ldata
ls.str(ldata)
eval(rexpr,envir=ldata)

## Do we need to get a model frame? How? and How to use it?

## Now ready to try things out.
```

# Tools for Jacobians

## numericDeriv() original version

`numericDeriv` is the R function used by `nls()` to evaluate Jacobians for its Gauss-Newton
equations. The R source code is in the file `nls.R`. It calls a C function numeric_deriv
in `nls.c`. 

```{r nd1}
## Seems to work -- BUT note file ExDerivs.R has many "failures"??
theta <- c("b1", "b2", "b3")
ndeunsc<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv)
print(ndeunsc)
print(sum(ndeunsc^2))
tndeunsc<-microbenchmark(ndeunsc<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv))
print(tndeunsc)
## numericDeriv also has central difference option, as well as choice of eps parameter
## Central diff
ndeunsc2<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE)
print(ndeunsc2)
print(sum(ndeunsc2^2))
tndeunsc2<-microbenchmark(ndeunsc2<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE))
print(tndeunsc2)

## Forward diff with smaller eps
ndeunscx<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, eps=1e-10)
print(ndeunscx)
print(sum(ndeunscx^2))
tndeunscx<-microbenchmark(ndeunscx2<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, eps=1e-10))
print(tndeunscx)

## Central diff with smaller eps
ndeunscx2<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE, eps=1e-10)
print(ndeunscx2)
print(sum(ndeunscx2^2))
tndeunscx2<-microbenchmark(ndeunscx2<-nlspkg::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE, eps=1e-10))
print(tndeunscx2)


```


## numericDeriv() alternative pure-R version

This version (see Appendix 2) has C code replaced with R equivalents.


```{r and1}
## Try ExDerivs.R ??
andeunsc<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv)
print(andeunsc)
print(sum(andeunsc^2))
tandeunsc<-microbenchmark(andeunsc<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv))
print(tandeunsc)
## numericDeriv also has central difference option, as well as choice of eps parameter
## Central diff
andeunsc2<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE)
print(andeunsc2)
print(sum(andeunsc2^2))
tandeunsc2<-microbenchmark(andeunsc2<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE))
print(tandeunsc2)

## Forward diff with smaller eps
andeunscx<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, eps=1e-10)
print(andeunscx)
print(sum(andeunscx^2))
tandeunscx<-microbenchmark(andeunscx2<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, eps=1e-10))
print(tandeunscx)

## Central diff with smaller eps
andeunscx2<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE, eps=1e-10)
print(andeunscx2)
print(sum(andeunscx2^2))
tandeunscx2<-microbenchmark(andeunscx2<-nlsalt::numericDeriv(rexpr, theta, rho=weedenv, central=TRUE, eps=1e-10))
print(tandeunscx2)
```

The `dir` parameter allows us to use a backward difference for the derivative. This 
appears in `nlsModel()` for the case where a parameter is on an upper bound for
the case `algorithm="port"`. It does not check for nearness to the bound, and 
for the lower bound assumes that we are stepping AWAY from the bound in the
default direction (`dir=+1`). None of the code addresses the issue where bounds
are closer together than the step used for the finite difference, so there are
situations where we could crash the code.



## Symbolic methods from `nlsr`

The package `nlsr` has a function `model2rjfun()` that converts an expression
describing how the residual functions are computed into an R function that
computes the residuals at a particular set of parameters and sets the 
**attribute** "gradient" of the vector of residual values to the Jacobian at
the particular set of parameters. 

```{r nlsr1}
# nlsr has function model2rjfun. We can evaluate just the residuals
res0<-model2rjfun(eunsc, start1, data=weeddata1, jacobian=FALSE)
res0(start1)
# or the residuals and jacobian
## nlsr::model2rjfun forms a function with gradient (jacobian) attribute
funsc <- model2rjfun(eunsc, start1, data=weeddata1) # from nlsr: creates a function
tmodel2rjfun <- microbenchmark(model2rjfun(eunsc, start1, data=weeddata1))
print(tmodel2rjfun)
print(funsc)
print(funsc(start1))
print(environment(funsc))
print(ls.str(environment(funsc)))
print(ls(environment(funsc)$data))
eval(eunsc, environment(funsc))
vfunsc<-funsc(start1)
print(vfunsc)
tfunsc<-microbenchmark(funsc(start1))
print(tfunsc)
```

# `numDeriv` package

The package `numDeriv` includes a function `jacobian()` that acts on a user
function `resid()` to produce the Jacobian at a set of parameters by several
choices of approximation. 

```{r numDeriv1}
# We use the residual function (without gradient attribute) from nlsr
jeunsc<-jacobian(res0, start1)
jeunsc
# Timings of the analytic jacobian calculations
tjeunsc<-microbenchmark(jeunsc<-jacobian(res0, start1))
print(tjeunsc)
```

Note that the manual pages for `numDeriv` offer many options for the functions in
the package. At 2021-5-27 we have yet to explore these.

# Comparisons

In the following, we are comparing to `vfunsc`, which is the evaluated 
residual vector at `start1=c(1,1,1)` with "gradient" attribute (jacobian)
included, as developed using package `nlsr`. This is taken as the "correct"
result, even though it is possible that the generated order of calculations
may introduce inaccuracies in the supposedly analytic derivatives.

`numericDeriv` computes a similar structure (residuals with "gradient" attribute):
`ndeunsc`: the forward difference result with default `eps` (1e-07 according to manual)
`ndeunsc2`: Central difference with default `eps`
`ndeunscx`: Forward difference with smaller eps=1e-10
`ndeunscx2`: Central difference with smaller eps=1e-10

`jeunsc`: numDeriv::jacobian() result with default settings.

```{r compjac1}
## Matrix comparisons
attr(ndeunsc, "gradient")-attr(vfunsc,"gradient")
attr(ndeunsc2, "gradient")-attr(vfunsc,"gradient")
attr(ndeunscx, "gradient")-attr(vfunsc,"gradient")
attr(ndeunscx2, "gradient")-attr(vfunsc,"gradient")
jeunsc-attr(vfunsc,"gradient")

## Summary comparisons
max(abs(attr(ndeunsc, "gradient")-attr(vfunsc,"gradient")))
max(abs(attr(ndeunsc2, "gradient")-attr(vfunsc,"gradient")))
max(abs(attr(ndeunscx, "gradient")-attr(vfunsc,"gradient")))
max(abs(attr(ndeunscx2, "gradient")-attr(vfunsc,"gradient")))
max(abs(jeunsc-attr(vfunsc,"gradient")))
```



# Performance results for different computing environments

Here we present tables of the results, preceded by identified descriptions of the machines we
used. We use ideas and functions from the document `MachineSummary` to provide a characterization
and identity for each machine used.

M21-LM20.1 

?? still to be run

?? What machines provide a range of possibilities.

## Appendix 1: Base R numericDeriv code

This code is in two files, nls.R and nls.c and is extracted here.

### From nls.R

```{r nlsR, comment=NA, echo=FALSE}
   cat(readLines('./nlsND.R'), sep = '\n')
```


### From nls.c

```{r nlsc, comment=NA, echo=FALSE}
   cat(readLines('./nlsND.c'), sep = '\n')
```

## Appendix 2: numericDeriv() from nlsalt package (all in R)

```{r nlsndnew, comment=NA, echo=FALSE}
   cat(readLines('./nlsalt/R/nlsnd.R'), sep = '\n')
```
